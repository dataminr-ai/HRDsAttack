{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare annotation data for the full task\n",
    "* This notebook demonstrates the workflow for preparing input dataframes to upload to AMT when launching annotation tasks.\n",
    "* Note that the steps shown here is for demonstration purposes only, the actual steps performed during the real annotation phase were different due to adjustment and revision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pprint\n",
    "import ujson\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "pd.options.display.max_columns=100\n",
    "\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_emoji_free_text(text):\n",
    "    return emoji.get_emoji_regexp().sub(r'', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Data EDA\n",
    "* Note that here we are using the sampled original GDELT data for demonstration, the unsampled original data is too big to reside in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataframes/sm_gdelt_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Column sampling\n",
    "* Only keep relevant columns\n",
    "* Remove NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = df[['GLOBALEVENTID', 'text', 'title', 'publish_date']]\n",
    "anno_df = anno_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Dedupe\n",
    "* Remove existing samples to avoid sample duplicates\n",
    "* Here we use the 5th batch as an example, skip this step if this is for the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1_df = pd.read_csv('../dataframes/amt_full_task_batch_1.csv')\n",
    "batch_2_df = pd.read_csv('../dataframes/amt_full_task_batch_2.csv')\n",
    "batch_3_df = pd.read_csv('../dataframes/amt_full_task_batch_3.csv')\n",
    "batch_4_df = pd.read_csv('../dataframes/amt_full_task_batch_4.csv')\n",
    "batch_1_ids = set(batch_1_df.GLOBALEVENTID.to_list())\n",
    "batch_2_ids = set(batch_2_df.GLOBALEVENTID.to_list())\n",
    "batch_3_ids = set(batch_3_df.GLOBALEVENTID.to_list())\n",
    "batch_4_ids = set(batch_4_df.GLOBALEVENTID.to_list())\n",
    "old_batch_ids = batch_1_ids.union(batch_2_ids).union(batch_3_ids).union(batch_4_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = anno_df[~(anno_df.GLOBALEVENTID.isin(old_batch_ids))]\n",
    "len(anno_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Keywords filtering & stratified sampling\n",
    "* Here we look for certain samples to balance the following classes: trade unionist, human right defenders, torture, and kidnapping\n",
    "* Then apply stratified sampling across all group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do keywords filtering before sampling\n",
    "# 1st filtering: trade unionist\n",
    "# 2nd filtering: human right defenders\n",
    "# 3rd filtering: torture\n",
    "# 4th filtering: kidnapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df_1 = anno_df[anno_df.text.str.contains('(?i)trade union')]\n",
    "len(anno_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df_2 = anno_df[anno_df.text.str.contains('(?i)human right')]\n",
    "len(anno_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df_3 = anno_df[anno_df.text.str.contains('(?i)torture')]\n",
    "len(anno_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df_4 = anno_df[anno_df.text.str.contains('(?i)kidnapping')]\n",
    "len(anno_df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 2 from each\n",
    "# we use 2 as example here, change this number for your specific case\n",
    "# for example, if total HITs = 100, then sample_n = 25\n",
    "sample_n = 2\n",
    "sample_1 = anno_df_1.sample(sample_n)\n",
    "sample_1_ids = set(sample_1.GLOBALEVENTID.to_list())\n",
    "\n",
    "sample_2 = anno_df_2[~(anno_df_2.GLOBALEVENTID.isin(sample_1_ids))].sample(sample_n)\n",
    "sample_2_ids = set(sample_2.GLOBALEVENTID.to_list()).union(sample_1_ids)\n",
    "\n",
    "sample_3 = anno_df_3[~(anno_df_3.GLOBALEVENTID.isin(sample_2_ids))].sample(sample_n)\n",
    "sample_3_ids = set(sample_3.GLOBALEVENTID.to_list()).union(sample_2_ids)\n",
    "\n",
    "sample_4 = anno_df_4[~(anno_df_4.GLOBALEVENTID.isin(sample_3_ids))].sample(sample_n)\n",
    "\n",
    "samples = pd.concat([sample_1, sample_2, sample_3, sample_4], ignore_index=True)\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Text Preprocessing\n",
    "* Removing emoji\n",
    "* Clean up publish date\n",
    "* Format news article text for HTML display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['text'] = samples.text.apply(give_emoji_free_text)\n",
    "samples['title'] = samples.title.apply(give_emoji_free_text)\n",
    "samples['publish_date'] = samples.publish_date.apply(lambda x: x.replace('+00:00', '') if x and '+00:00' in x else x)\n",
    "samples['article_interface'] = samples.text.apply(lambda x: ' '.join(['<p>'+i+'</p>' for i in x.split('\\n') if i.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['batch_idx'] = 5\n",
    "samples = samples[['GLOBALEVENTID', 'title', 'publish_date', 'article_interface', 'batch_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no duplicated articles\n",
    "len(set(samples.article_interface.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "samples.to_csv('../dataframes/amt_full_task_batch_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
