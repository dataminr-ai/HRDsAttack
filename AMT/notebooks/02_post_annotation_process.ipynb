{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Annotation Processing\n",
    "* This notebook illustrates all the data processing steps involved in handling annotated data from the full task. Including:\n",
    "* * Converting raw AMT output to more readable JSON data objects;\n",
    "* * Calculate inter-annotater agreement;\n",
    "* * Merge multiple annotations to one following a set of merging rules;\n",
    "* * Basic statistics analysis of the processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pprint\n",
    "import ujson\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample(df_sample):\n",
    "    \n",
    "    \"\"\"\n",
    "    convert an annotated dataframe into a list of JSON objects\n",
    "    \"\"\"\n",
    "    \n",
    "    res = {}\n",
    "    sample_info = {}\n",
    "    worker_info = {}\n",
    "    annotation = {}\n",
    "    # parse existing info\n",
    "    input_keys = [i for i in df_sample.keys() if 'Input.' in i]\n",
    "    for input_key in input_keys:\n",
    "        sample_info[input_key] = df_sample[input_key]\n",
    "    sample_info['HIT_id'] = df_sample['HITId']\n",
    "    \n",
    "    worker_info['worker_id'] = df_sample['WorkerId']\n",
    "    worker_info['work_time_in_seconds'] = df_sample['WorkTimeInSeconds']\n",
    "    \n",
    "    # add base info\n",
    "    annotation.update(get_base_info(df_sample))\n",
    "    \n",
    "    # add victims\n",
    "    annotation['victims'] = get_victims(df_sample)\n",
    "    \n",
    "    worker_info['annotation'] = annotation\n",
    "    \n",
    "    res['sample'] = sample_info\n",
    "    res['worker'] = worker_info\n",
    "    \n",
    "    return res\n",
    "    \n",
    "    \n",
    "def get_base_info(df_sample):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parse base attributes such as perpetrators, violation types, locations, and time\n",
    "    \"\"\"\n",
    "    \n",
    "    # get perpetrator mention\n",
    "    perp_mention_key = 'Answer.perpetrator_mention_true_1.perpetrator_mention_true_1'\n",
    "    perp_mentioned = df_sample[perp_mention_key]\n",
    "    \n",
    "    # get perpetrator type\n",
    "    if perp_mentioned:\n",
    "        perp_type_keys = [i for i in df_sample.keys() if '_actor_' in i] + ['Answer.insufficient_info_1_0.insufficient_info_1_0']\n",
    "        for perp_type_key in perp_type_keys:\n",
    "            if df_sample[perp_type_key]:\n",
    "                if 'insufficient_info_' in perp_type_key:\n",
    "                    perp_type = 'insufficient info'\n",
    "                elif 'state_actor_' in perp_type_key:\n",
    "                    perp_type = 'state actor'\n",
    "                elif 'other_actor_w_' in perp_type_key:\n",
    "                    perp_type = 'other actors with permissions'\n",
    "                elif 'other_actor_wo_' in perp_type_key:\n",
    "                    perp_type = 'other actors without permissions'\n",
    "                elif 'other_actor_na_' in perp_type_key:\n",
    "                    perp_type = 'other actors with unknown permissions'\n",
    "                else:\n",
    "                    perp_type = 'error type'\n",
    "                break\n",
    "    else:\n",
    "        perp_type = None\n",
    "    \n",
    "    # get violationt types\n",
    "    violation_type_keys = [i for i in df_sample.keys() if 'Answer.abuse_type_' in i]\n",
    "    violation_types = []\n",
    "    for violation_type_key in violation_type_keys:\n",
    "        if df_sample[violation_type_key]:\n",
    "            if '_arbitrary_detention_' in violation_type_key:\n",
    "                violation_type = 'arbitrary detention'\n",
    "            elif '_enforced_disappearance_' in violation_type_key:\n",
    "                violation_type = 'enforced disappearance'\n",
    "            elif '_kidnapping_' in violation_type_key:\n",
    "                violation_type = 'kidnapping'\n",
    "            elif '_killing_' in violation_type_key:\n",
    "                violation_type = 'killing'\n",
    "            elif '_torture_' in violation_type_key:\n",
    "                violation_type = 'torture'\n",
    "            elif '_other_' in violation_type_key:\n",
    "                violation_type = 'other'\n",
    "            else:\n",
    "                violation_type = 'error type'\n",
    "            violation_types.append(violation_type)\n",
    "    \n",
    "    # get time info\n",
    "    year_input = str(int(df_sample['Answer.year_incident_1'])) if df_sample['Answer.year_incident_1'] else None\n",
    "    month_input = str(df_sample['Answer.month_incident_1']) if df_sample['Answer.month_incident_1'] else None\n",
    "    date_input = str(df_sample['Answer.date_incident_1']) if df_sample['Answer.date_incident_1'] else None\n",
    "    \n",
    "    # get location info\n",
    "    city_input = str(df_sample['Answer.location_city_1'])\n",
    "    region_input = str(df_sample['Answer.location_region_1'])\n",
    "    country_input = str(df_sample['Answer.location_country_1'])\n",
    "    \n",
    "    return {\n",
    "        'perpetrator_mention': perp_mentioned,\n",
    "        'perpetrator_type': perp_type,\n",
    "        'violation_types': violation_types,\n",
    "        'year': year_input,\n",
    "        'month': month_input,\n",
    "        'date': date_input,\n",
    "        'city': city_input,\n",
    "        'region': region_input,\n",
    "        'country': country_input,\n",
    "    }\n",
    "\n",
    "def get_victims(df_sample):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parse victim annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the maximal number of victims\n",
    "    max_num_vic = len([i for i in df_sample.keys() if 'Answer.victim_pop_type_multiple_1' in i])\n",
    "    # get the actual number of victims\n",
    "    num_vic = len([i for i in range(1, max_num_vic+1) if df_sample['Answer.victim_pop_type_multiple_1_'+str(i)+'.victim_pop_type_multiple_1_'+str(i)] \n",
    "                   is not None])\n",
    "    vics = []\n",
    "    pop_keys = [i for i in df_sample.keys() if 'Answer.victim_pop_type_' in i]\n",
    "    for vic_idx in range(1, num_vic+1):\n",
    "        # get population type\n",
    "        pop_key_multi = 'Answer.victim_pop_type_multiple_1_'+str(vic_idx)+'.victim_pop_type_multiple_1_'+str(vic_idx)\n",
    "        if df_sample[pop_key_multi]:\n",
    "            pop_type = \"multiple\"\n",
    "        else:\n",
    "            pop_type = \"individual\"\n",
    "        # get name\n",
    "        if pop_type == \"individual\":\n",
    "            vic_name_key = 'Answer.victim_name_1_'+str(vic_idx)\n",
    "            vic_name = df_sample[vic_name_key]\n",
    "        else:\n",
    "            vic_name = None\n",
    "        # get keywords\n",
    "        vic_keywords_key = 'Answer.victim_keywords_1_'+str(vic_idx)\n",
    "        vic_keywords = df_sample[vic_keywords_key]\n",
    "        # get victim types\n",
    "        vic_type_keys = [i for i in df_sample.keys() if 'Answer.victim_type_' in i]\n",
    "        vic_types = []\n",
    "        for vic_type_key in vic_type_keys:\n",
    "            if vic_type_key[-1] == str(vic_idx) and df_sample[vic_type_key]:\n",
    "                if 'journalist' in vic_type_key:\n",
    "                    vic_type = 'journalist'\n",
    "                elif 'trade_unionist' in vic_type_key:\n",
    "                    vic_type = 'trade unionist'\n",
    "                elif '_hrd_' in vic_type_key:\n",
    "                    vic_type = 'human rights defender'\n",
    "                elif '_na_' in vic_type_key:\n",
    "                    vic_type = 'insufficient information'\n",
    "                else:\n",
    "                    vic_type = 'error type'\n",
    "                vic_types.append(vic_type)\n",
    "        # get victim sex type\n",
    "        vic_sex_keys = [i for i in df_sample.keys() if 'Answer.victim_sex_type_' in i]\n",
    "        for vic_sex_key in vic_sex_keys:\n",
    "            if vic_sex_key[-1] == str(vic_idx) and df_sample[vic_sex_key]:\n",
    "                if '_man_' in vic_sex_key:\n",
    "                    vic_sex_type = 'man'\n",
    "                elif '_woman_' in vic_sex_key:\n",
    "                    vic_sex_type = 'woman'\n",
    "                elif '_other_' in vic_sex_key:\n",
    "                    vic_sex_type = 'other'\n",
    "                elif '_unkown_' in vic_sex_key:\n",
    "                    vic_sex_type = 'unknown'\n",
    "                else:\n",
    "                    vic_sex_type = 'error type'\n",
    "                break\n",
    "        # get age group\n",
    "        vic_age_keys = [i for i in df_sample.keys() if 'Answer.victim_age_group_' in i]\n",
    "        for vic_age_key in vic_age_keys:\n",
    "            if vic_age_key[-1] == str(vic_idx) and df_sample[vic_age_key]:\n",
    "                if '_adult_' in vic_age_key:\n",
    "                    vic_age_type = 'adult'\n",
    "                elif '_child_' in vic_age_key:\n",
    "                    vic_age_type = 'child'\n",
    "                elif '_other_' in vic_age_key:\n",
    "                    vic_age_type = 'other'\n",
    "                elif '_unknown_' in vic_age_key:\n",
    "                    vic_age_type = 'unknown'\n",
    "                else:\n",
    "                    vic_age_type = 'error type'\n",
    "                break\n",
    "        vics.append({\n",
    "            'victim_idx': vic_idx,\n",
    "            'victim_population_type': pop_type,\n",
    "            'victim_name': vic_name,\n",
    "            'victim_keywords': vic_keywords,\n",
    "            'victim_type': vic_types,\n",
    "            'victim_sex_type': vic_sex_type,\n",
    "            'victim_age_group': vic_age_type,\n",
    "        })\n",
    "    return vics\n",
    "\n",
    "\n",
    "def merge_annotations(annotated_samples):\n",
    "    \"\"\"\n",
    "    merge replicated annotations (from 3 workers) into one report per sample but with annotations from all three workers\n",
    "    \"\"\"\n",
    "    merged_samples = []\n",
    "    HIT_ids = {i['sample']['HIT_id'] for i in annotated_samples}\n",
    "    for HIT_id in HIT_ids:\n",
    "        merged_sample = {}\n",
    "        HITs = [i for i in annotated_samples if i['sample']['HIT_id'] == HIT_id]\n",
    "        assert HITs[0]['sample'] == HITs[1]['sample'] == HITs[2]['sample']\n",
    "        merged_sample['sample'] = HITs[0]['sample']\n",
    "        merged_sample['annotations'] = []\n",
    "        for HIT in HITs:\n",
    "            merged_sample['annotations'].append(HIT['worker'])\n",
    "        merged_samples.append(merged_sample)\n",
    "    return merged_samples\n",
    "\n",
    "\n",
    "def norm_label(label):\n",
    "    \"\"\"\n",
    "    normalize the label if the label is None, convert it to \"None\"\n",
    "    \"\"\"\n",
    "    return \"None\" if not label else str(label)\n",
    "\n",
    "\n",
    "def norm_score(score):\n",
    "    \"\"\"\n",
    "    normalize the score if the score is nan, convert it to 0\n",
    "    \"\"\"\n",
    "    return 0 if np.isnan(score) else score\n",
    "\n",
    "\n",
    "def flat_nested_dict(input_dict):\n",
    "    res_dict = {}\n",
    "    for key, item in input_dict.items():\n",
    "        if type(item) != dict:\n",
    "            res_dict[key] = item\n",
    "        else:\n",
    "            for child_key, child_item in item.items():\n",
    "                res_dict[key+'_'+child_key] = child_item\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def convert_annotation_df(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df1 = df.where(pd.notnull(df), None)\n",
    "    samples = df1.to_dict('records')\n",
    "    res_samples = [convert_sample(i) for i in samples]\n",
    "    return res_samples\n",
    "\n",
    "\n",
    "def merge_sample(sample):\n",
    "    \n",
    "    merged_annotation = {}\n",
    "        \n",
    "    for key in text_input_keys:\n",
    "        ans_list = [[i['worker_id'], i['annotation'][key]] for i in sample['annotations'] \n",
    "                    if i['annotation'][key] and i['annotation'][key]!='None']\n",
    "        if not ans_list:\n",
    "            merged_annotation[key] = None\n",
    "#         elif len(ans_list) == 1:\n",
    "#             merged_annotation[key] = ans_list[0][1]\n",
    "        else:\n",
    "            val_cnt = Counter([i[1] for i in ans_list])\n",
    "            # if majority exist, take majority vote\n",
    "            if len(val_cnt) != len(ans_list):\n",
    "                merged_annotation[key] = val_cnt.most_common(1)[0][0]\n",
    "            # if not, take answer from the better worker\n",
    "            else:\n",
    "                merged_annotation[key] = sorted(ans_list, key=lambda x: worker_qa_score[x[0]])[-1][1]\n",
    "    \n",
    "    for key in selection_input_keys:\n",
    "        # take majority vote (has to happen)\n",
    "        if key == 'perpetrator_mention':\n",
    "            ans_list = [[i['worker_id'], i['annotation'][key]] for i in sample['annotations']]\n",
    "            val_cnt = Counter([i[1] for i in ans_list])\n",
    "            merged_annotation[key] = val_cnt.most_common(1)[0][0]\n",
    "        elif key == 'perpetrator_type':\n",
    "            if merged_annotation['perpetrator_mention']:\n",
    "                # if did mention, 1) take majority vote; 2) better worker otherwise\n",
    "                # only look at the workers who picked yes\n",
    "                worker_ids = [i['worker_id'] for i in sample['annotations'] if i['annotation']['perpetrator_mention']]\n",
    "                ans_list = [[i['worker_id'], i['annotation'][key]] for i in sample['annotations'] if i['worker_id'] in worker_ids]\n",
    "                val_cnt = Counter([i[1] for i in ans_list])\n",
    "                # if majority exist, take majority vote\n",
    "                if len(val_cnt) != len(ans_list):\n",
    "                    merged_annotation[key] = val_cnt.most_common(1)[0][0]\n",
    "                # if not, take answer from the better worker\n",
    "                else:\n",
    "                    merged_annotation[key] = sorted(ans_list, key=lambda x: worker_qa_score[x[0]])[-1][1]\n",
    "            else:\n",
    "                # if did not mention, pass in None\n",
    "                merged_annotation[key] = None\n",
    "        else:\n",
    "            # in general, take majority or better worker\n",
    "            ans_list = [[i['worker_id'], i['annotation'][key]] for i in sample['annotations']]\n",
    "            val_cnt = Counter([i[1] for i in ans_list])\n",
    "            # if majority exist, take majority vote\n",
    "            if len(val_cnt) != len(ans_list):\n",
    "                merged_annotation[key] = val_cnt.most_common(1)[0][0]\n",
    "            # if not, take answer from the better worker\n",
    "            else:\n",
    "                merged_annotation[key] = sorted(ans_list, key=lambda x: worker_qa_score[x[0]])[-1][1]\n",
    "    \n",
    "    for key in list_input_keys:\n",
    "        ans_list = [[i['worker_id'], i['annotation'][key]] for i in sample['annotations']]\n",
    "        # take from the better worker\n",
    "        merged_annotation[key] = sorted(ans_list, key=lambda x: -worker_qa_score[x[0]])[0][1]\n",
    "    \n",
    "    return merged_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load and parse the raw output dataframe\n",
    "* After loading, convert the data format first\n",
    "* Then merge the same HITs from multiple workers into a single record containing multiple annotations from all workers using `merge_annotations`. Note this is different from merging within the sample using `merge_sample` where all replicated annotations for a single HIT is merged using a set of rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataframes/full_task_results/Batch_4797737_batch_results_full_1.csv')\n",
    "df1 = df.where(pd.notnull(df), None)\n",
    "samples = df1.to_dict('records')\n",
    "res_samples = [convert_sample(i) for i in samples]\n",
    "merged_samples = merge_annotations(res_samples)\n",
    "pprint.pprint(random.choice(merged_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Calculate inter-annotator agreement\n",
    "1. Inter-annotator agreement is calculated by Pair-wise Cohen-Kappa score\n",
    "2. on these tags: 1). Perpetrator mention; 2). Perpetrator Type; 3). First violation type; 4). First victim population type; 5). First victim type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps to evaluate each worker:\n",
    "#    for each unique worker id:\n",
    "#    locate the related merged samples \n",
    "#    calculate pair-wise cohen-kappa for the five questions\n",
    "#    average two pair-wise scores to generate a score per question\n",
    "#    average 5 scores to get final agreement score for this worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_ids = list({i['worker']['worker_id'] for i in res_samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_value_keys = ['perpetrator_mention', 'perpetrator_type']\n",
    "first_choice_keys = ['violation_types']\n",
    "first_victim_keys = ['victim_population_type']\n",
    "first_victim_fist_choice_keys = ['victim_type']\n",
    "\n",
    "score_list = []\n",
    "\n",
    "for worker_id in worker_ids:\n",
    "    worker_scores = {}\n",
    "    # get HITs that this worker finished\n",
    "    worker_HITs = [i for i in merged_samples if worker_id in [j['worker_id'] for j in i['annotations']]]\n",
    "    # get annotations that are NOT from this worker, instead from the other two workers\n",
    "    paired_annotations = []\n",
    "    worker_annotations = []\n",
    "    for worker_HIT in worker_HITs:\n",
    "        worker_annotations.append([i for i in worker_HIT['annotations'] if i['worker_id']==worker_id][0])\n",
    "        paired_annotations.append([i for i in worker_HIT['annotations'] if i['worker_id']!=worker_id])\n",
    "    add_worker1_annotations, add_worker2_annotations = [list(i) for i in zip(*paired_annotations)]\n",
    "    \n",
    "    for single_value_key in single_value_keys:\n",
    "        worker_labels = [norm_label(i['annotation'][single_value_key]) for i in worker_annotations]\n",
    "        add_worker1_labels = [norm_label(i['annotation'][single_value_key]) for i in add_worker1_annotations]\n",
    "        add_worker2_labels = [norm_label(i['annotation'][single_value_key]) for i in add_worker2_annotations]\n",
    "        \n",
    "        #calculate scores\n",
    "        pair1_score = cohen_kappa_score(worker_labels, add_worker1_labels)\n",
    "        pair2_score = cohen_kappa_score(worker_labels, add_worker2_labels)\n",
    "        worker_scores[single_value_key] = norm_score((pair1_score + pair2_score) / 2)\n",
    "    \n",
    "    for first_choice_key in first_choice_keys:\n",
    "        worker_labels = [norm_label(i['annotation'][first_choice_key][0]) for i in worker_annotations]\n",
    "        add_worker1_labels = [norm_label(i['annotation'][first_choice_key][0]) for i in add_worker1_annotations]\n",
    "        add_worker2_labels = [norm_label(i['annotation'][first_choice_key][0]) for i in add_worker2_annotations]\n",
    "        #calculate scores\n",
    "        pair1_score = cohen_kappa_score(worker_labels, add_worker1_labels)\n",
    "        pair2_score = cohen_kappa_score(worker_labels, add_worker2_labels)\n",
    "        worker_scores[first_choice_key] = norm_score((pair1_score + pair2_score) / 2)\n",
    "        \n",
    "    for first_victim_key in first_victim_keys:\n",
    "        worker_labels = [norm_label(i['annotation']['victims'][0][first_victim_key]) for i in worker_annotations]\n",
    "        add_worker1_labels = [norm_label(i['annotation']['victims'][0][first_victim_key]) for i in add_worker1_annotations]\n",
    "        add_worker2_labels = [norm_label(i['annotation']['victims'][0][first_victim_key]) for i in add_worker2_annotations]\n",
    "        #calculate scores\n",
    "        pair1_score = cohen_kappa_score(worker_labels, add_worker1_labels)\n",
    "        pair2_score = cohen_kappa_score(worker_labels, add_worker2_labels)\n",
    "        worker_scores[first_victim_key] = norm_score((pair1_score + pair2_score) / 2)\n",
    "        \n",
    "    for first_victim_fist_choice_key in first_victim_fist_choice_keys:\n",
    "        worker_labels = [norm_label(i['annotation']['victims'][0][first_victim_fist_choice_key][0]) for i in worker_annotations]\n",
    "        add_worker1_labels = [norm_label(i['annotation']['victims'][0][first_victim_fist_choice_key][0]) for i in add_worker1_annotations]\n",
    "        add_worker2_labels = [norm_label(i['annotation']['victims'][0][first_victim_fist_choice_key][0]) for i in add_worker2_annotations]\n",
    "        #calculate scores\n",
    "        pair1_score = cohen_kappa_score(worker_labels, add_worker1_labels)\n",
    "        pair2_score = cohen_kappa_score(worker_labels, add_worker2_labels)\n",
    "        worker_scores[first_victim_fist_choice_key] = norm_score((pair1_score + pair2_score) / 2)\n",
    "        \n",
    "    score_list.append({\n",
    "        'worker_id': worker_id,\n",
    "        'scores': worker_scores,\n",
    "        'num_HITs_done': len(worker_annotations),\n",
    "        'avg_score': sum(list(worker_scores.values()))/len(worker_scores)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = sorted(score_list, key=lambda x: -x['avg_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame([flat_nested_dict(i) for i in score_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Merge samples via majority voting/merging\n",
    "* Rules for merging the samples:\n",
    "1. for text input answers, if only one answer exists (two None), take the only answer; If more than one exists, take the answer from the worker that has higher qualification scores\n",
    "2. for single choice answers, take majority vote, if no majority, take the answer from the worker that has higher qualification scores\n",
    "3. for victim answers, take the victim list that has the most number of victims, if tie, take the list from the worker that has higher qualification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the worker IDs are anonymized.\n",
    "worker_qa_score = {\n",
    "    'da86f058-00ca-4ec2-b63e-b87f42dab844': 82,\n",
    "    'fd5ebe40-5dbb-4a22-b959-6cf3d0ae0829': 75,\n",
    "    '24528428-dbe4-46d7-bd43-27324cef42f6': 80,\n",
    "    '7b387f77-1f0b-48dd-b77d-ff8b7e2af7ef': 84,\n",
    "    '7b8989dd-46ba-4242-a051-7457344fba3d': 98,\n",
    "    '1f400fe4-8bb5-413a-ba43-1c46576aeb51': 91,\n",
    "    '3da648d3-cbda-4938-8d40-4afce6ed7973': 82,\n",
    "    'ac287307-81d2-4211-a19d-c6a1c38a754a': 77,\n",
    "    'ea7ca118-9f34-4464-9425-0be339155b76': 75,\n",
    "    'cfe772f1-9e88-4332-850f-791cd09c3fd2': 84,\n",
    "}\n",
    "\n",
    "text_input_keys = {'city', 'country', 'date', 'month', 'region', 'year'}\n",
    "selection_input_keys = ['perpetrator_mention', 'perpetrator_type']\n",
    "list_input_keys = {'victims', 'violation_types'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in merged_samples:\n",
    "    i['merged_sample'] = merge_sample(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../processed_annotated_data/full_batch_1.json', 'w')  as json_file:\n",
    "    ujson.dump(merged_samples, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Worker distrubution\n",
    "df.WorkerId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of samples DOES NOT have explicit perpetrator mentions\n",
    "mentioned_samples = [i for i in merged_samples if i['merged_sample']['perpetrator_mention']]\n",
    "print(\"Ratio: {}\".format(round(len(mentioned_samples)/len(merged_samples), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Average number of victims\n",
    "print(\"Avg. # Victims: {}\".format(np.mean([len(i['merged_sample']['victims']) for i in merged_samples])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
